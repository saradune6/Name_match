{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d9d359-f141-4bb3-a765-172243b9fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = [\n",
    "    \"traders\",\"trading\", \"enterprise\", \"garments\", \"collection\", \"food\", \"clothes\",'fashion', \n",
    "    \"glass\", \"fittings\", \"digital\", \"kirana\", \"medical\", \"agency\",\"tex\",\n",
    "    \"security\", \"systems\", \"badges\", \"hospitality\", \"jewellers\", \n",
    "    \"ready-made\", \"store\", \"hospital\", \"restaurant\", \"auto\", \"center\", \n",
    "    \"dairy\", \"home\", \"products\", \"services\", \"furniture\", \"hardware\", \n",
    "    \"pharmacy\", \"stationery\", \"treatments\", \"nutrition\", \"wellness\", \n",
    "    \"sweets\", \"resort\", \"kitchen\", \"clothing\", \"fashion\", \"market\", \n",
    "    \"poultry\", \"seeds\", \"pesticides\", \"sales\", \"cafe\", \"clinic\", \n",
    "    \"supermart\", \"distributors\", \"automobiles\", \"electricity\", \n",
    "    \"electronics\", \"general\", \"provision\", \"fertilizers\", \"agriculture\", \n",
    "    \"beverages\", \"textiles\", \"plumbing\", \"supplies\", \"handicrafts\", \n",
    "    \"construction\", \"medical\", \"bakery\", \"tissue\", \"cleaning\", \n",
    "    \"appliances\", \"homecare\", \"kitchenware\", \"decor\", \"glass and fittings\",\n",
    "    \"interiors\", \"shopping\", \"crafts\", \"tools\", \"wholesale\", \n",
    "    \"retail\", \"outlet\", \"merchants\", \"trade\", \"distribution\", \n",
    "    \"solutions\", \"innovation\", \"consultancy\", \"services\", \"equipment\", \n",
    "    \"manufacturing\", \"exports\", \"imports\", \"packaging\", \"network\", \n",
    "    \"consultants\", \"transport\", \"moving\", \"storage\", \"logistics\", \n",
    "    \"construction\", \"real estate\", \"brokerage\", \"management\", \n",
    "    \"finance\", \"investment\", \"funding\", \"support\", \"technology\", \n",
    "    \"software\", \"applications\", \"digital marketing\", \"advertising\", \n",
    "    \"communication\", \"entertainment\", \"events\", \"tourism\", \"travel\", \n",
    "    \"transportation\", \"automotive\", \"services\", \"supply chain\", \n",
    "    \"fashion\", \"cosmetics\", \"beauty\", \"spa\", \"wellness\", \"glass and fitting\",\n",
    "    \"personal care\", \"gifts\", \"custom\", \"specialty\", \"craftsmanship\", \n",
    "    \"fashions\", \"motors\", \"enterprises\", \"garment\", \"cloth centre\", \"mart\", \n",
    "    \"foods\", \"silk and readymade\", \"wool centre\", \"jewellery\", \"mill\", \n",
    "    \"farms\", \"farm\", \"electrical\", \"egg centre\", \"centre\", \n",
    "    \"vegetable and fruits\", \"vegetables\", \"fruits\", \"pvt\", \"pvt ltd\", \n",
    "    \"limited\", \"solutions\", \"energies\", \"photo\", \"studio\", \"works\", \n",
    "    \"associates\", \"medico\", \"agencies\", \"diagnosis\", \"cool drinks\", \n",
    "    \"drinks\", \"care\", \"liquor\", \"automobiles\", \"materials\", \"diagnostics\", \n",
    "    \"provision\", \"trader\", \"farms\", \"farm\", \"stations\", \"restaurant\", \n",
    "    \"creations\", \"travels\", \"hardware\", \"printers\", \"graphics\", \n",
    "    \"fertilisers\", \"house\", \"studio\", \"private\", \"appliances\", \"steels\", \n",
    "    \"shop\", \"metals\", \"international\", \"jwellers\", \"corporation\", \n",
    "    \"dresses\", \"industries\", \"electricals\", \"company\", \"lim\", \"colddrinks\", \n",
    "    \"electron\", \"medicines\", \"llc\", \"computers\", \"hotel\", \"spa\", \n",
    "    \"cosmetics\", \"telecom\", \"sarees\", \"petroleums\", \"bhandar\",'store','stores', \n",
    "    \"surgical\", \"wines\", \"constructions\", \"shoppy\", \"lab\", \"builders\", \n",
    "    \"footwear\", \"wear\", \"shoe\", \"repair\", \"ventures\", \"paint\", \"depot\",'cake','chinies',\n",
    "    \"tent\", \"decorators\", \"communications\", \"pharmacy\", \"products\",'textile','CERAMIC','Pharmaceuticals',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad309b1-e1e1-476a-bae1-842499d00cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.80\n",
    "\n",
    "\n",
    "##------------------------------------Fuzzy Wuzzy Layer-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## Layer 1 - Fuzzy Wuzzy Without Preprocessing\n",
    "def calculate_fuzzy_similarity(name1, name2):\n",
    "    fuzzy_ratio = fuzz.ratio(name1, name2) / 100.0\n",
    "    fuzzy_partial_ratio = fuzz.partial_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_sort_ratio = fuzz.token_sort_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_set_ratio = fuzz.token_set_ratio(name1, name2) / 100.0\n",
    "\n",
    "    fuzzy_similarity = (fuzzy_ratio + fuzzy_partial_ratio + fuzzy_token_sort_ratio + fuzzy_token_set_ratio) / 4.0\n",
    "    return fuzzy_similarity\n",
    "\n",
    "#-----------------------------------------Data Preprocessing anf Framework--------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# layer 4 over here \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import jellyfish\n",
    "\n",
    "# Regular expressions for different patterns\n",
    "SPECIAL_CHAR_DOT_REGEX = r\"[.]\"\n",
    "SPECIAL_CHARS_REGEX = r\"[-+.^:,_/\\s]+\" \n",
    "SALUTATION_REGEX = r\"^(shree|shri|miss|smt|mrs|mr|ms|dr|master|hon|sir|madam|prof|capt|major|rev|fr|br)\\s*\"\n",
    "PARENT_SPOUSE_NAME_REGEX = r\"(?:\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of)\\s*)\"\n",
    "COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX = r\"\\b(mohammad|mohammed|muhamed|mohd|mohamed|mohamad|muhamad|muhammad|muhammed|muhammet|mohamud|mohummad|mohummed|mouhamed|muhamaad|mohammod|mouhamad|mo|md|mahmood|mahmud|ahmad|ahmed|hameed|hamid|hammed|mahd|mahmod|mohd|mouhammed|mohamad|muhmood|mohhammed|muhmamed|mohmed|mohmat|muhmat|mu|m|shaikh|mo)\\b\"\n",
    "LAST_NAMES_AGARWAL_VARIANTS_REGEX = r\"\\b(aggarwal|agrawal|agarwal|aggrawal|agarwalla|agarwal)\\b\"\n",
    "\n",
    "\n",
    "# Preprocessing functions\n",
    "def convert_to_lower(name):\n",
    "    return name.lower()\n",
    "\n",
    "def replace_adjacent_duplicates(value):\n",
    "    if isinstance(value, str):\n",
    "        return re.sub(r'(.)\\1+', r'\\1', value)\n",
    "    return value\n",
    "\n",
    "def replace_characters(name):\n",
    "    replacements = {'e': 'i', 'j': 'z', 'v': 'w', 'q': 'k'}\n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    return name\n",
    "\n",
    "def replace_bigrams(name):\n",
    "    replacements = {'ph': 'f', 'gh': 'g', 'th': 't', 'kh': 'k', 'dh': 'd', 'ch': 'c', 'sh': 's', 'au': 'o',\n",
    "                    'bh': 'b', 'ks': 'x', 'ck': 'k', 'ah': 'h', 'wh': 'w', 'wr': 'r'}\n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    return name\n",
    "\n",
    "def remove_extra_spaces(name):\n",
    "    return re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "def remove_consonant_a(name):\n",
    "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "    new_name = ''.join([name[i] for i in range(len(name)) if not (i > 0 and name[i] == 'a' and name[i - 1].lower() in consonants)])\n",
    "    return new_name\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub(SPECIAL_CHAR_DOT_REGEX, '', text)\n",
    "    text = re.sub(SPECIAL_CHARS_REGEX, '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_salutations(text):\n",
    "    return re.sub(SALUTATION_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_parent_spouse_name(text):\n",
    "    return re.sub(r'\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of|daughter|son|child of)\\s*[\\w\\s,.]*$', '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_common_muslim_variations(text):\n",
    "    return re.sub(COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_agarwal_variants(text):\n",
    "    return re.sub(LAST_NAMES_AGARWAL_VARIANTS_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = ['devi', 'dei', 'debi', 'kumar', 'kumaar', 'kumari', 'kumaari', 'kmr', 'kumr', 'bhai', 'bhau', 'bai', 'ben', 'singh', 'kaur', 'Md', 'Mohd', 'Mohammad', 'Mohamad']\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def preprocess(name):\n",
    "    name = remove_salutations(name)\n",
    "    name = remove_parent_spouse_name(name)\n",
    "    name = remove_common_muslim_variations(name)\n",
    "    name = remove_agarwal_variants(name)\n",
    "    name = convert_to_lower(name)\n",
    "    name = replace_adjacent_duplicates(name)\n",
    "    name = replace_characters(name)\n",
    "    name = replace_bigrams(name)\n",
    "    name = remove_consonant_a(name)\n",
    "    name = remove_special_characters(name)\n",
    "    name = remove_extra_spaces(name)\n",
    "    name = remove_stop_words(name)\n",
    "    return name\n",
    "\n",
    "# Load pre-trained models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Similarity functions\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1, embedding2).item()\n",
    "\n",
    "def calculate_levenshtein_similarity(name1, name2):\n",
    "    lev_distance = levenshtein_distance(name1, name2)\n",
    "    max_len = max(len(name1), len(name2))\n",
    "    return (max_len - lev_distance) / max_len if max_len > 0 else 1.0\n",
    "\n",
    "def calculate_phonetic_similarity(name1, name2):\n",
    "    soundex1 = jellyfish.soundex(name1)\n",
    "    soundex2 = jellyfish.soundex(name2)\n",
    "    return jellyfish.jaro_winkler_similarity(soundex1, soundex2)\n",
    "\n",
    "def calculate_jaccard_similarity(name1, name2):\n",
    "    set1, set2 = set(name1), set(name2)\n",
    "    intersection, union = set1.intersection(set2), set1.union(set2)\n",
    "    return len(intersection) / len(union) if union else 1.0\n",
    "\n",
    "##------------------------------------Calling Name_Match------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Layer 2 similarity function\n",
    "def name_match(name1, name2):\n",
    "    name1_processed = preprocess(name1)\n",
    "    name2_processed = preprocess(name2)\n",
    "\n",
    "    embedding1 = get_embedding(name1_processed)\n",
    "    embedding2 = get_embedding(name2_processed)\n",
    "    embedding_similarity = calculate_cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "    levenshtein_similarity = calculate_levenshtein_similarity(name1_processed, name2_processed)\n",
    "    phonetic_similarity = calculate_phonetic_similarity(name1_processed, name2_processed)\n",
    "    jaccard_similarity = calculate_jaccard_similarity(name1_processed, name2_processed)\n",
    "\n",
    "    fuzzy_ratio = fuzz.ratio(name1_processed, name2_processed) / 100.0\n",
    "    fuzzy_partial_ratio = fuzz.partial_ratio(name1_processed, name2_processed) / 100.0\n",
    "    fuzzy_token_sort_ratio = fuzz.token_sort_ratio(name1_processed, name2_processed) / 100.0\n",
    "    fuzzy_token_set_ratio = fuzz.token_set_ratio(name1_processed, name2_processed) / 100.0\n",
    "\n",
    "    fuzzy_similarity = (fuzzy_ratio + fuzzy_partial_ratio + fuzzy_token_sort_ratio + fuzzy_token_set_ratio) / 4.0\n",
    "\n",
    "    # Weighted average of similarity metrics\n",
    "    final_score = (\n",
    "        embedding_similarity * 0.3 +\n",
    "        levenshtein_similarity * 0.2 +\n",
    "        phonetic_similarity * 0.3 +\n",
    "        jaccard_similarity * 0.4 +\n",
    "        fuzzy_similarity * 0.6\n",
    "    )\n",
    "    return final_score\n",
    "\n",
    "#----------------------------------------Initials Matching Without Preprocessing---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Layer 3 - Initials Matching Without Preprocessing\n",
    "def check_initial_similarity(name1, name2):\n",
    "    initials1 = [word[0].upper() for word in name1.split() if word]\n",
    "    initials2 = [word[0].upper() for word in name2.split() if word]\n",
    "\n",
    "    if not initials1 or not initials2:\n",
    "        return 0.0\n",
    "    \n",
    "    return 1.0 if set(initials1).issubset(set(initials2)) or set(initials2).issubset(set(initials1)) else 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##------------------------------------Fuzzy With Data Preprocessing-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "SPECIAL_CHAR_DOT_REGEX = r\"[.]\"\n",
    "SPECIAL_CHARS_REGEX = r\"[-+.^:,_/\\s]+\" \n",
    "SALUTATION_REGEX = r\"^(shree|shri|miss|smt|mrs|mr|ms|dr|master|hon|sir|madam|prof|capt|major|rev|fr|br)\\s*\"\n",
    "PARENT_SPOUSE_NAME_REGEX = r\"(?:\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of)\\s*)\"\n",
    "COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX = r\"\\b(mohammad|mohammed|muhamed|mohd|mohamed|mohamad|muhamad|muhammad|muhammed|muhammet|mohamud|mohummad|mohummed|mouhamed|muhamaad|mohammod|mouhamad|mo|md|mahmood|mahmud|ahmad|ahmed|hameed|hamid|hammed|mahd|mahmod|mohd|mouhammed|mohamad|muhmood|mohhammed|muhmamed|mohmed|mohmat|muhmat|mu|m|shaikh|mo)\\b\"\n",
    "LAST_NAMES_AGARWAL_VARIANTS_REGEX = r\"\\b(aggarwal|agrawal|agarwal|aggrawal|agarwalla|agarwal)\\b\"\n",
    "\n",
    "\n",
    "# Preprocessing functions\n",
    "def convert_to_lower(name):\n",
    "    return name.lower()\n",
    "\n",
    "def remove_extra_spaces(name):\n",
    "    return re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "def remove_common_muslim_variations(text):\n",
    "    return re.sub(COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_agarwal_variants(text):\n",
    "    return re.sub(LAST_NAMES_AGARWAL_VARIANTS_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = ['devi', 'dei', 'debi', 'kumar', 'kumaar', 'kumari', 'kumaari', 'kmr', 'kumr', 'bhai', 'bhau', 'bai', 'ben', 'singh', 'kaur', 'Md', 'Mohd', 'Mohammad', 'Mohamad']\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    " #  processing only for failed  of layer 3\n",
    "def preprocess_FuzzyWuzzy(name):\n",
    "    \"\"\"Process a name through all the defined normalization steps.\"\"\"\n",
    "    name = convert_to_lower(name)\n",
    "    name = remove_stop_words(name)\n",
    "    name = remove_common_muslim_variations(name)\n",
    "    name = remove_agarwal_variants(name)\n",
    "    return name\n",
    "\n",
    "def calculate_fuzzy_similarity_processed(name1, name2):\n",
    "    name1 = preprocess_FuzzyWuzzy(name1)\n",
    "    name2 = preprocess_FuzzyWuzzy(name2)\n",
    "    \n",
    "    fuzzy_ratio = fuzz.ratio(name1, name2) / 100.0\n",
    "    fuzzy_partial_ratio = fuzz.partial_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_sort_ratio = fuzz.token_sort_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_set_ratio = fuzz.token_set_ratio(name1, name2) / 100.0\n",
    "\n",
    "    fuzzy_similarity = (fuzzy_ratio + fuzzy_partial_ratio + fuzzy_token_sort_ratio + fuzzy_token_set_ratio) / 4.0\n",
    "    return fuzzy_similarity\n",
    "\n",
    "def check_keywords_in_names(name1, name2):\n",
    "    \"\"\"Check for presence of keywords in either or both names.\"\"\"\n",
    "    found_in_name1 = any(keyword in name1.lower() for keyword in KEYWORDS)\n",
    "    found_in_name2 = any(keyword in name2.lower() for keyword in KEYWORDS)\n",
    "    \n",
    "    if found_in_name1 and found_in_name2:\n",
    "        return 1  # Flag remains 1 if keyword found in both names\n",
    "    elif found_in_name1 or found_in_name2:\n",
    "        return 0  # Flag set to 0 if keyword found in either name\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff95c2e-d252-4026-9b07-4e5d2da9436d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with new predictions and indicator column:\n",
      "         id merchant_type                 created_at     status docType  \\\n",
      "0  47566417   UNORGANIZED  2024-01-01 12:53:41+00:00  ACTIVATED  PAN_NO   \n",
      "1  48465215   UNORGANIZED  2024-02-14 14:22:48+00:00  ACTIVATED  PAN_NO   \n",
      "2  48036361   UNORGANIZED  2024-01-29 16:40:52+00:00  ACTIVATED  PAN_NO   \n",
      "3  46063565   UNORGANIZED  2023-10-06 19:39:01+00:00  ACTIVATED  PAN_NO   \n",
      "4  45539504           DIY  2023-09-12 19:00:36+00:00  ACTIVATED  PAN_NO   \n",
      "\n",
      "               name                     pan_createdAt pan_status  \\\n",
      "0             DAILI         2024-01-01 07:36:53+00:00   APPROVED   \n",
      "1  UMESH KUMAR NAIK  2024-02-14 09:00:02.613000+00:00   APPROVED   \n",
      "2      KSHAMA GUPTA  2024-01-29 11:18:32.509000+00:00   APPROVED   \n",
      "3      AFJAL ANSARI         2023-10-06 14:20:17+00:00   APPROVED   \n",
      "4         AMIN ALAM         2023-09-12 13:38:57+00:00   APPROVED   \n",
      "\n",
      "          beneficiary_name bank_status  ... First_Layer_Pass  Prediction  \\\n",
      "0                    DAILI      ACTIVE  ...             True        True   \n",
      "1              SUJAL KUMAR      ACTIVE  ...            False        True   \n",
      "2  JATASHANKAR ENTERPRISES      ACTIVE  ...            False       False   \n",
      "3            Afjal  Ansari      ACTIVE  ...            False        True   \n",
      "4               AMIN  ALAM      ACTIVE  ...             True        True   \n",
      "\n",
      "  Second_Layer_Score Second_Layer_Pass Third_Layer_Score  Third_Layer_Pass  \\\n",
      "0                NaN               NaN               NaN               NaN   \n",
      "1           0.953814              True               NaN               NaN   \n",
      "2           0.449095             False               0.0             False   \n",
      "3           1.800000              True               NaN               NaN   \n",
      "4                NaN               NaN               NaN               NaN   \n",
      "\n",
      "   Fourth_Layer_Score Fourth_Layer_Pass  Updated_Prediction  \\\n",
      "0                 NaN               NaN                True   \n",
      "1                 NaN               NaN               False   \n",
      "2            0.449095             False               False   \n",
      "3                 NaN               NaN                True   \n",
      "4                 NaN               NaN                True   \n",
      "\n",
      "   Prediction_Updated  \n",
      "0               False  \n",
      "1                True  \n",
      "2               False  \n",
      "3               False  \n",
      "4               False  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        10303           28\n",
      "Actual 1            1        10170\n",
      "\n",
      "Correlation Matrix:\n",
      "                          id  szFlag   dsScore  szScore   flScore     SCORE  \\\n",
      "id                  1.000000     NaN -0.027826      NaN  0.019066  0.020089   \n",
      "szFlag                   NaN     NaN       NaN      NaN       NaN       NaN   \n",
      "dsScore            -0.027826     NaN  1.000000      NaN  0.100611  0.998056   \n",
      "szScore                  NaN     NaN       NaN      NaN       NaN       NaN   \n",
      "flScore             0.019066     NaN  0.100611      NaN  1.000000  0.893569   \n",
      "SCORE               0.020089     NaN  0.998056      NaN  0.893569  1.000000   \n",
      "labels              0.020322     NaN  0.516676      NaN  0.930848  0.935229   \n",
      "First_Layer_Score   0.006455     NaN  0.449603      NaN  0.862994  0.850939   \n",
      "Second_Layer_Score  0.018694     NaN  0.361976      NaN  0.827594  0.795545   \n",
      "Third_Layer_Score   0.023313     NaN  0.058810      NaN  0.235424  0.125665   \n",
      "Fourth_Layer_Score  0.033531     NaN  0.186505      NaN  0.093717  0.186078   \n",
      "\n",
      "                      labels  First_Layer_Score  Second_Layer_Score  \\\n",
      "id                  0.020322           0.006455            0.018694   \n",
      "szFlag                   NaN                NaN                 NaN   \n",
      "dsScore             0.516676           0.449603            0.361976   \n",
      "szScore                  NaN                NaN                 NaN   \n",
      "flScore             0.930848           0.862994            0.827594   \n",
      "SCORE               0.935229           0.850939            0.795545   \n",
      "labels              1.000000           0.856413            0.835388   \n",
      "First_Layer_Score   0.856413           1.000000            0.773506   \n",
      "Second_Layer_Score  0.835388           0.773506            1.000000   \n",
      "Third_Layer_Score   0.220085           0.138906            0.024890   \n",
      "Fourth_Layer_Score  0.002108           0.301407            1.000000   \n",
      "\n",
      "                    Third_Layer_Score  Fourth_Layer_Score  \n",
      "id                           0.023313            0.033531  \n",
      "szFlag                            NaN                 NaN  \n",
      "dsScore                      0.058810            0.186505  \n",
      "szScore                           NaN                 NaN  \n",
      "flScore                      0.235424            0.093717  \n",
      "SCORE                        0.125665            0.186078  \n",
      "labels                       0.220085            0.002108  \n",
      "First_Layer_Score            0.138906            0.301407  \n",
      "Second_Layer_Score           0.024890            1.000000  \n",
      "Third_Layer_Score            1.000000                 NaN  \n",
      "Fourth_Layer_Score                NaN            1.000000  \n",
      "\n",
      "Metrics:\n",
      "Accuracy: 0.9985855038532826\n",
      "Precision: 0.9972543636007061\n",
      "Recall: 0.9999016812506145\n",
      "F1 Score: 0.9985762678580196\n",
      "AUC: 0.9985956959152114\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def process_name_matching(file_path):\n",
    "# def process_name_matching(file_path, num_rows=10):\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    # df=df.head(100)\n",
    "    # df = pd.read_csv(file_path, nrows=num_rows)\n",
    "    threshold = 0.80\n",
    "\n",
    "    # Layer 1: Fuzzy Matching Without Preprocessing\n",
    "    df[\"First_Layer_Score\"] = df.apply(lambda x: calculate_fuzzy_similarity(x['name1'], x['name2']), axis=1)\n",
    "    df[\"First_Layer_Pass\"] = df[\"First_Layer_Score\"] >= threshold\n",
    "    df_layer2 = df[~df[\"First_Layer_Pass\"]].copy()\n",
    "\n",
    "    # Layer 2: Preprocessed Fuzzy Matching\n",
    "    df_layer2[\"Second_Layer_Score\"] = df_layer2.apply(lambda x: name_match(x['name1'], x['name2']), axis=1)\n",
    "    df_layer2[\"Second_Layer_Pass\"] = df_layer2[\"Second_Layer_Score\"] >= threshold\n",
    "    df_layer3 = df_layer2[~df_layer2[\"Second_Layer_Pass\"]].copy()\n",
    "\n",
    "    # Layer 3: Initials Matching Without Preprocessing\n",
    "    df_layer3[\"Third_Layer_Score\"] = df_layer3.apply(lambda x: check_initial_similarity(x['name1'], x['name2']), axis=1)\n",
    "    df_layer3[\"Third_Layer_Pass\"] = df_layer3[\"Third_Layer_Score\"] >= threshold\n",
    "    df_layer4 = df_layer3[~df_layer3[\"Third_Layer_Pass\"]].copy()\n",
    "\n",
    "    # Layer 4: Model and Phonetic Matching\n",
    "    df_layer4[\"Fourth_Layer_Score\"] = df_layer4.apply(lambda x: name_match(x['name1'], x['name2']), axis=1)\n",
    "    df_layer4[\"Fourth_Layer_Pass\"] = df_layer4[\"Fourth_Layer_Score\"] >= threshold\n",
    "    \n",
    "\n",
    "\n",
    "    # Save layers and results\n",
    "    df_combined = pd.concat([\n",
    "        df[df[\"First_Layer_Pass\"]],\n",
    "        df_layer2[df_layer2[\"Second_Layer_Pass\"]],\n",
    "        df_layer3[df_layer3[\"Third_Layer_Pass\"]],\n",
    "        df_layer4[df_layer4[\"Fourth_Layer_Pass\"]],\n",
    "\n",
    "    ])\n",
    "    df_combined.to_csv(\"File.csv\",index=False)\n",
    "    # Updating Prediction status based on layer passes\n",
    "    df[\"Prediction\"] = False\n",
    "    df.loc[df[\"First_Layer_Pass\"], \"Prediction\"] = True\n",
    "    df.loc[df_layer2.index[df_layer2[\"Second_Layer_Pass\"]], \"Prediction\"] = True\n",
    "    df.loc[df_layer3.index[df_layer3[\"Third_Layer_Pass\"]], \"Prediction\"] = True\n",
    "    df.loc[df_layer4.index[df_layer4[\"Fourth_Layer_Pass\"]], \"Prediction\"] = True\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # df[\"Layer0_Pass\"] = df.get(\"Layer0_Pass\", None)\n",
    "    df[\"First_Layer_Score\"] = df.get(\"First_Layer_Score\", None)\n",
    "    df[\"First_Layer_Pass\"] = df.get(\"First_Layer_Pass\", None)\n",
    "    df[\"Second_Layer_Score\"] = df_layer2.get(\"Second_Layer_Score\", None)\n",
    "    df[\"Second_Layer_Pass\"] = df_layer2.get(\"Second_Layer_Pass\", None)\n",
    "    df[\"Third_Layer_Score\"] = df_layer3.get(\"Third_Layer_Score\", None)\n",
    "    df[\"Third_Layer_Pass\"] = df_layer3.get(\"Third_Layer_Pass\", None)\n",
    "    df[\"Fourth_Layer_Score\"] = df_layer4.get(\"Fourth_Layer_Score\", None)\n",
    "    df[\"Fourth_Layer_Pass\"] = df_layer4.get(\"Fourth_Layer_Pass\", None)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    # Save the main DataFrame to CSV\n",
    "    df.to_csv('Api_fun_result.csv')\n",
    "\n",
    "    # Filter data for labels = 0 and Prediction = True\n",
    "    filtered_data = df[(df['labels'] == 0) & (df['Prediction'] == True)]\n",
    "\n",
    "    # Initialize columns for new Prediction and indicator\n",
    "    df['Updated_Prediction'] = df['Prediction']  # Default to current Prediction\n",
    "    df['Prediction_Updated'] = False  # Default indicator to False\n",
    "\n",
    "    # Iterate through the main DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        if index in filtered_data.index:\n",
    "            # Apply custom logic for rows in filtered_data\n",
    "            name1 = row['name1']\n",
    "            name2 = row['name2']\n",
    "            fuzzy_SS = calculate_fuzzy_similarity_processed(name1, name2)\n",
    "\n",
    "            # Set fuzzy flag based on similarity threshold\n",
    "            fuzzy_flag = 1 if fuzzy_SS >= 0.80 else 0\n",
    "            if fuzzy_flag == 1:\n",
    "                fuzzy_flag = check_keywords_in_names(name1, name2)\n",
    "\n",
    "            prediction_value = True if fuzzy_flag == 1 else False\n",
    "\n",
    "            # Update the Prediction column and set the indicator to True\n",
    "            df.at[index, 'Updated_Prediction'] = prediction_value\n",
    "            df.at[index, 'Prediction_Updated'] = True\n",
    "        else:\n",
    "            # Leave Updated_Prediction as is and Prediction_Updated as False\n",
    "            df.at[index, 'Updated_Prediction'] = row['Prediction']\n",
    "\n",
    "    # Save the updated DataFrame to CSV\n",
    "    df.to_csv('Filtered_Api_fun_result_with_updates.csv', index=False)\n",
    "\n",
    "    # Performance metrics using the updated predictions\n",
    "    y_true = df['labels']\n",
    "    y_pred = df['Updated_Prediction']\n",
    "    # y_scores = df['First_Layer_Score']  # Use First_Layer_Score for ROC AUC score\n",
    "    y_scores = df['Updated_Prediction'].astype(float) \n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc_score\": roc_auc_score(y_true, y_scores),\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "        \"classification_report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "    # Correlation matrix (only numeric columns)\n",
    "    correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "    print(\"Updated DataFrame with new predictions and indicator column:\")\n",
    "    print(df.head())\n",
    "\n",
    "#    new code ending\n",
    "    \n",
    "    \n",
    "#     data = df[(df['labels'] == 0) & (df['Prediction'] == True)]\n",
    "\n",
    "#     # Performance metrics\n",
    "#     y_true = df['labels']\n",
    "#     y_pred = df['Prediction']\n",
    "#     y_scores = df[\"First_Layer_Score\"]  # Use the scores for AUC\n",
    "\n",
    "#     metrics = {\n",
    "#         \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "#         \"precision\": precision_score(y_true, y_pred),\n",
    "#         \"recall\": recall_score(y_true, y_pred),\n",
    "#         \"f1_score\": f1_score(y_true, y_pred),\n",
    "#         \"roc_auc_score\": roc_auc_score(y_true, y_scores),\n",
    "#         \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "#         \"classification_report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "#     }\n",
    "\n",
    "#     # Correlation matrix (only numeric columns)\n",
    "#     correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "    return metrics, df, df_combined, correlation_matrix\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"2_lakh_NM_Manually.csv\", num_rows=10)\n",
    "    metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"20k_balaned_data.csv\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "    cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm_df)\n",
    "\n",
    "    # Print the correlation matrix\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    # Print other metrics\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']}\")\n",
    "    print(f\"AUC: {metrics['roc_auc_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804ea68-f419-465e-8ee3-2b21b147fb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c799fc87-263b-4df8-b454-d29f57f97276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keywords_in_names(name1, name2):\n",
    "    \"\"\"Check for presence of keywords in either or both names.\"\"\"\n",
    "    found_in_name1 = any(keyword in name1.lower() for keyword in KEYWORDS)\n",
    "    found_in_name2 = any(keyword in name2.lower() for keyword in KEYWORDS)\n",
    "    \n",
    "    if found_in_name1 and found_in_name2:\n",
    "        return 1  # Flag remains 1 if keyword found in both names\n",
    "    elif found_in_name1 or found_in_name2:\n",
    "        return 0  # Flag set to 0 if keyword found in either name\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbe4c7-44a2-4160-9db0-7403ee73d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f25ecd-b199-4be9-b08c-5c4dc61ceb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3157848-bd29-4904-8237-210716cafc6e",
   "metadata": {},
   "source": [
    "## last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ba006-b833-490b-913d-269979cf83d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee734c98-a227-43e9-8a62-9a6324215729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz  # Add this import for fuzzy matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e212d45-e19f-4fd7-9c34-48c635016d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data_fail = pd.read_csv(\"Api_fun_result.csv\")\n",
    "data = df_data_fail[(df_data_fail['labels'] == 0) & (df_data_fail['Prediction'] == True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be78bf61-9125-4128-adcc-88b0adac64a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            3670\n",
       "id                    3670\n",
       "merchant_type         3670\n",
       "created_at            3670\n",
       "status                3670\n",
       "docType               3670\n",
       "name                  3670\n",
       "pan_createdAt         3670\n",
       "pan_status            3670\n",
       "beneficiary_name      3670\n",
       "bank_status           3670\n",
       "account_number        3670\n",
       "szFlag                   0\n",
       "hvFlag                 220\n",
       "name1                 3670\n",
       "name2                 3670\n",
       "dsScore               3628\n",
       "flFlag                3670\n",
       "dsFlag                3628\n",
       "szScore                  0\n",
       "flScore               3670\n",
       "SCORE                 3670\n",
       "labels                3670\n",
       "First_Layer_Score     3670\n",
       "First_Layer_Pass      3670\n",
       "Prediction            3670\n",
       "Second_Layer_Score    3661\n",
       "Second_Layer_Pass     3661\n",
       "Third_Layer_Score      506\n",
       "Third_Layer_Pass       506\n",
       "Fourth_Layer_Score       0\n",
       "Fourth_Layer_Pass        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d709d764-4612-4bdd-aa9b-a616d526cd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "KEYWORDS = [\n",
    "    \"traders\", \"enterprise\", \"garments\", \"collection\", \"food\", \"clothes\",'fashion', \n",
    "    \"glass\", \"fittings\", \"digital\", \"kirana\", \"medical\", \"agency\", \n",
    "    \"security\", \"systems\", \"badges\", \"hospitality\", \"jewellers\", \n",
    "    \"ready-made\", \"store\", \"hospital\", \"restaurant\", \"auto\", \"center\", \n",
    "    \"dairy\", \"home\", \"products\", \"services\", \"furniture\", \"hardware\", \n",
    "    \"pharmacy\", \"stationery\", \"treatments\", \"nutrition\", \"wellness\", \n",
    "    \"sweets\", \"resort\", \"kitchen\", \"clothing\", \"fashion\", \"market\", \n",
    "    \"poultry\", \"seeds\", \"pesticides\", \"sales\", \"cafe\", \"clinic\", \n",
    "    \"supermart\", \"distributors\", \"automobiles\", \"electricity\", \n",
    "    \"electronics\", \"general\", \"provision\", \"fertilizers\", \"agriculture\", \n",
    "    \"beverages\", \"textiles\", \"plumbing\", \"supplies\", \"handicrafts\", \n",
    "    \"construction\", \"medical\", \"bakery\", \"tissue\", \"cleaning\", \n",
    "    \"appliances\", \"homecare\", \"kitchenware\", \"decor\", \"glass and fittings\",\n",
    "    \"interiors\", \"shopping\", \"crafts\", \"tools\", \"wholesale\", \n",
    "    \"retail\", \"outlet\", \"merchants\", \"trade\", \"distribution\", \n",
    "    \"solutions\", \"innovation\", \"consultancy\", \"services\", \"equipment\", \n",
    "    \"manufacturing\", \"exports\", \"imports\", \"packaging\", \"network\", \n",
    "    \"consultants\", \"transport\", \"moving\", \"storage\", \"logistics\", \n",
    "    \"construction\", \"real estate\", \"brokerage\", \"management\", \n",
    "    \"finance\", \"investment\", \"funding\", \"support\", \"technology\", \n",
    "    \"software\", \"applications\", \"digital marketing\", \"advertising\", \n",
    "    \"communication\", \"entertainment\", \"events\", \"tourism\", \"travel\", \n",
    "    \"transportation\", \"automotive\", \"services\", \"supply chain\", \n",
    "    \"fashion\", \"cosmetics\", \"beauty\", \"spa\", \"wellness\", \"glass and fitting\",\n",
    "    \"personal care\", \"gifts\", \"custom\", \"specialty\", \"craftsmanship\", \n",
    "    \"fashions\", \"motors\", \"enterprises\", \"garment\", \"cloth centre\", \"mart\", \n",
    "    \"foods\", \"silk and readymade\", \"wool centre\", \"jewellery\", \"mill\", \n",
    "    \"farms\", \"farm\", \"electrical\", \"egg centre\", \"centre\", \n",
    "    \"vegetable and fruits\", \"vegetables\", \"fruits\", \"pvt\", \"pvt ltd\", \n",
    "    \"limited\", \"solutions\", \"energies\", \"photo\", \"studio\", \"works\", \n",
    "    \"associates\", \"medico\", \"agencies\", \"diagnosis\", \"cool drinks\", \n",
    "    \"drinks\", \"care\", \"liquor\", \"automobiles\", \"materials\", \"diagnostics\", \n",
    "    \"provision\", \"trader\", \"farms\", \"farm\", \"stations\", \"restaurant\", \n",
    "    \"creations\", \"travels\", \"hardware\", \"printers\", \"graphics\", \n",
    "    \"fertilisers\", \"house\", \"studio\", \"private\", \"appliances\", \"steels\", \n",
    "    \"shop\", \"metals\", \"international\", \"jwellers\", \"corporation\", \n",
    "    \"dresses\", \"industries\", \"electricals\", \"company\", \"lim\", \"colddrinks\", \n",
    "    \"electron\", \"medicines\", \"llc\", \"computers\", \"hotel\", \"spa\", \n",
    "    \"cosmetics\", \"telecom\", \"sarees\", \"petroleums\", \"bhandar\",'store','stores', \n",
    "    \"surgical\", \"wines\", \"constructions\", \"shoppy\", \"lab\", \"builders\", \n",
    "    \"footwear\", \"wear\", \"shoe\", \"repair\", \"ventures\", \"paint\", \"depot\",'cake','chinies',\n",
    "    \"tent\", \"decorators\", \"communications\", \"pharmacy\", \"products\",'textile','CERAMIC','Pharmaceuticals',\n",
    "]\n",
    "\n",
    "\n",
    "SPECIAL_CHAR_DOT_REGEX = r\"[.]\"\n",
    "SPECIAL_CHARS_REGEX = r\"[-+.^:,_/\\s]+\" \n",
    "SALUTATION_REGEX = r\"^(shree|shri|miss|smt|mrs|mr|ms|dr|master|hon|sir|madam|prof|capt|major|rev|fr|br)\\s*\"\n",
    "PARENT_SPOUSE_NAME_REGEX = r\"(?:\\s*(?:s/o|d/o|w/o|so|do|wo|daughter of|son of|wife of|husband of)\\s*)\"\n",
    "COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX = r\"\\b(mohammad|mohammed|muhamed|mohd|mohamed|mohamad|muhamad|muhammad|muhammed|muhammet|mohamud|mohummad|mohummed|mouhamed|muhamaad|mohammod|mouhamad|mo|md|mahmood|mahmud|ahmad|ahmed|hameed|hamid|hammed|mahd|mahmod|mohd|mouhammed|mohamad|muhmood|mohhammed|muhmamed|mohmed|mohmat|muhmat|mu|m|shaikh|mo)\\b\"\n",
    "LAST_NAMES_AGARWAL_VARIANTS_REGEX = r\"\\b(aggarwal|agrawal|agarwal|aggrawal|agarwalla|agarwal)\\b\"\n",
    "\n",
    "\n",
    "# Preprocessing functions\n",
    "def convert_to_lower(name):\n",
    "    return name.lower()\n",
    "\n",
    "def remove_extra_spaces(name):\n",
    "    return re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "def remove_common_muslim_variations(text):\n",
    "    return re.sub(COMMON_MUSLIM_SALUTATIONS_MOHAMMAD_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_agarwal_variants(text):\n",
    "    return re.sub(LAST_NAMES_AGARWAL_VARIANTS_REGEX, '', text, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = ['devi', 'dei', 'debi', 'kumar', 'kumaar', 'kumari', 'kumaari', 'kmr', 'kumr', 'bhai', 'bhau', 'bai', 'ben', 'singh', 'kaur', 'Md', 'Mohd', 'Mohammad', 'Mohamad']\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "def check_keywords_in_names(name1, name2):\n",
    "    \"\"\"Check for presence of keywords in either or both names.\"\"\"\n",
    "    found_in_name1 = any(keyword in name1.lower() for keyword in KEYWORDS)\n",
    "    found_in_name2 = any(keyword in name2.lower() for keyword in KEYWORDS)\n",
    "    \n",
    "    if found_in_name1 and found_in_name2:\n",
    "        return 1  # Flag remains 1 if keyword found in both names\n",
    "    elif found_in_name1 or found_in_name2:\n",
    "        return 0  # Flag set to 0 if keyword found in either name\n",
    "    return 1\n",
    "\n",
    " #  processing only for failed  of layer 3\n",
    "def preprocess_FuzzyWuzzy(name):\n",
    "    \"\"\"Process a name through all the defined normalization steps.\"\"\"\n",
    "    name = convert_to_lower(name)\n",
    "    name = remove_stop_words(name)\n",
    "    name = remove_common_muslim_variations(name)\n",
    "    name = remove_agarwal_variants(name)\n",
    "    return name\n",
    "\n",
    "def calculate_fuzzy_similarity_processed(name1, name2):\n",
    "    name1 = preprocess_FuzzyWuzzy(name1)\n",
    "    name2 = preprocess_FuzzyWuzzy(name2)\n",
    "    \n",
    "    fuzzy_ratio = fuzz.ratio(name1, name2) / 100.0\n",
    "    fuzzy_partial_ratio = fuzz.partial_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_sort_ratio = fuzz.token_sort_ratio(name1, name2) / 100.0\n",
    "    fuzzy_token_set_ratio = fuzz.token_set_ratio(name1, name2) / 100.0\n",
    "\n",
    "    fuzzy_similarity = (fuzzy_ratio + fuzzy_partial_ratio + fuzzy_token_sort_ratio + fuzzy_token_set_ratio) / 4.0\n",
    "    return fuzzy_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d808865d-97c3-4333-8dc7-4bfd4f84666d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "mismatched_data = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    name1 = row['name1']\n",
    "    name2 = row['name2']\n",
    "    fuzzy_SS = calculate_fuzzy_similarity_processed(name1, name2)\n",
    "\n",
    "    fuzzy_flag = 1 if fuzzy_SS >= 0.80 else 0\n",
    "    if fuzzy_flag == 1:\n",
    "        fuzzy_flag = check_keywords_in_names(name1, name2)\n",
    "\n",
    "    prediction_value = True if fuzzy_flag == 1 else False\n",
    "\n",
    "    # Assuming these columns exist in your `data1` DataFrame; adjust if necessary\n",
    "    result_row = {\n",
    "        'id': row['id'],\n",
    "        'name1': name1,\n",
    "        'name2': name2,\n",
    "        'dsScore': row['dsScore'],\n",
    "        'flScore': row['flScore'],\n",
    "        'SCORE': row['SCORE'],\n",
    "        'labels': row['labels'],\n",
    "        'fuzzy_SS': fuzzy_SS,  \n",
    "        'fuzzy_flag': fuzzy_flag,\n",
    "        'First_Layer_Score': row['First_Layer_Score'],\n",
    "        'First_Layer_Pass': row['First_Layer_Pass'],\n",
    "        'Prediction': prediction_value,\n",
    "        'Second_Layer_Score': row['Second_Layer_Score'],\n",
    "        'Second_Layer_Pass': row['Second_Layer_Pass'],\n",
    "        'Third_Layer_Score': row['Third_Layer_Score'],\n",
    "        'Third_Layer_Pass': row['Third_Layer_Pass'],\n",
    "        'Fourth_Layer_Score': row['Fourth_Layer_Score'],\n",
    "        'Fourth_Layer_Pass': row['Fourth_Layer_Pass']\n",
    "    }\n",
    "\n",
    "    if row['labels'] == fuzzy_flag:\n",
    "        results.append(result_row)\n",
    "    else:\n",
    "        mismatched_data.append(result_row)\n",
    "\n",
    "results_df1 = pd.DataFrame(results)\n",
    "mismatched_data1_df = pd.DataFrame(mismatched_data)\n",
    "\n",
    "# Display mismatched data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2f7e54-8352-444c-9a68-5ba0bd51872c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# name1='SATYENDRA KUMAR PAL'\n",
    "# name2= 'SATYENDRA PHARMACY'\n",
    "# fuzzy_SS = calculate_fuzzy_similarity_processed(name1, name2)\n",
    "# fuzzy_SS\n",
    "# if fuzzy_flag == 1:\n",
    "#         fuzzy_flag = check_keywords_in_names(name1, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f73a8acf-118a-48b3-a16f-84621882c194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    30\n",
       "name1                 30\n",
       "name2                 30\n",
       "dsScore               29\n",
       "flScore               30\n",
       "SCORE                 30\n",
       "labels                30\n",
       "fuzzy_SS              30\n",
       "fuzzy_flag            30\n",
       "First_Layer_Score     30\n",
       "First_Layer_Pass      30\n",
       "Prediction            30\n",
       "Second_Layer_Score    25\n",
       "Second_Layer_Pass     25\n",
       "Third_Layer_Score      0\n",
       "Third_Layer_Pass       0\n",
       "Fourth_Layer_Score     0\n",
       "Fourth_Layer_Pass      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatched_data1_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81477342-ff0a-440e-a72b-37f7ffa3876f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name1</th>\n",
       "      <th>name2</th>\n",
       "      <th>dsScore</th>\n",
       "      <th>flScore</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>labels</th>\n",
       "      <th>fuzzy_SS</th>\n",
       "      <th>fuzzy_flag</th>\n",
       "      <th>First_Layer_Score</th>\n",
       "      <th>First_Layer_Pass</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Second_Layer_Score</th>\n",
       "      <th>Second_Layer_Pass</th>\n",
       "      <th>Third_Layer_Score</th>\n",
       "      <th>Third_Layer_Pass</th>\n",
       "      <th>Fourth_Layer_Score</th>\n",
       "      <th>Fourth_Layer_Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48465215</td>\n",
       "      <td>UMESH KUMAR NAIK</td>\n",
       "      <td>SUJAL KUMAR</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.953814</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48659500</td>\n",
       "      <td>KHILENDRA KANT KHARE</td>\n",
       "      <td>KHULESH KANT KHARE S O GYAN DAS KARE</td>\n",
       "      <td>73.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.026215</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49415422</td>\n",
       "      <td>KUSHAL MARJIT</td>\n",
       "      <td>KUSHAL GLASS AND FITTINGS</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.021844</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47694926</td>\n",
       "      <td>GARRE LAKSHMI HARIKA</td>\n",
       "      <td>DIVVELA LAKSHMI HARIKA</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.310948</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49690637</td>\n",
       "      <td>AMRIT LAL GAUR</td>\n",
       "      <td>THE MODERN MAN</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.809096</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>49952832</td>\n",
       "      <td>AVINASH SRIVASTAVA</td>\n",
       "      <td>SADDA CHINESE ADDA</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.787139</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>47951499</td>\n",
       "      <td>KAMAL KUMAR AGARWALA</td>\n",
       "      <td>Ronak Raghuwanshi</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.817186</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>50771868</td>\n",
       "      <td>SAEED AHMAD</td>\n",
       "      <td>M/S SONA TRADERS</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.045242</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>47210669</td>\n",
       "      <td>SADANANDAM DESHINI</td>\n",
       "      <td>SHIVA WINES KAMALAPU</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.829727</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>47368581</td>\n",
       "      <td>RAJ KUMAR</td>\n",
       "      <td>R K MEDICOSE</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.885107</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3640 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 name1                                 name2  \\\n",
       "0     48465215      UMESH KUMAR NAIK                           SUJAL KUMAR   \n",
       "1     48659500  KHILENDRA KANT KHARE  KHULESH KANT KHARE S O GYAN DAS KARE   \n",
       "2     49415422         KUSHAL MARJIT           KUSHAL GLASS AND FITTINGS     \n",
       "3     47694926  GARRE LAKSHMI HARIKA                DIVVELA LAKSHMI HARIKA   \n",
       "4     49690637        AMRIT LAL GAUR                        THE MODERN MAN   \n",
       "...        ...                   ...                                   ...   \n",
       "3635  49952832    AVINASH SRIVASTAVA                    SADDA CHINESE ADDA   \n",
       "3636  47951499  KAMAL KUMAR AGARWALA                     Ronak Raghuwanshi   \n",
       "3637  50771868           SAEED AHMAD                    M/S SONA TRADERS     \n",
       "3638  47210669    SADANANDAM DESHINI                  SHIVA WINES KAMALAPU   \n",
       "3639  47368581             RAJ KUMAR                          R K MEDICOSE   \n",
       "\n",
       "      dsScore  flScore  SCORE  labels  fuzzy_SS  fuzzy_flag  \\\n",
       "0        1.72     0.00   1.72       0    0.2325           0   \n",
       "1       73.63     0.00  73.63       0    0.6250           0   \n",
       "2       23.22     0.50  23.22       0    0.5250           0   \n",
       "3        0.44     0.00   0.44       0    0.7850           0   \n",
       "4       29.00     0.00  29.00       0    0.2925           0   \n",
       "...       ...      ...    ...     ...       ...         ...   \n",
       "3635    44.00     0.00  44.00       0    0.4175           0   \n",
       "3636    38.00     0.00  38.00       0    0.4000           0   \n",
       "3637    35.00     0.00  35.00       0    0.3350           0   \n",
       "3638    26.00     0.00  26.00       0    0.2650           0   \n",
       "3639    38.00     0.33  38.00       0    0.1800           0   \n",
       "\n",
       "      First_Layer_Score  First_Layer_Pass  Prediction  Second_Layer_Score  \\\n",
       "0                0.5750             False       False            0.953814   \n",
       "1                0.6250             False       False            1.026215   \n",
       "2                0.5175             False       False            1.021844   \n",
       "3                0.7850             False       False            1.310948   \n",
       "4                0.2925             False       False            0.809096   \n",
       "...                 ...               ...         ...                 ...   \n",
       "3635             0.4175             False       False            0.787139   \n",
       "3636             0.2750             False       False            0.817186   \n",
       "3637             0.3825             False       False            1.045242   \n",
       "3638             0.2650             False       False            0.829727   \n",
       "3639             0.3950             False       False            0.885107   \n",
       "\n",
       "     Second_Layer_Pass  Third_Layer_Score Third_Layer_Pass  \\\n",
       "0                 True                NaN              NaN   \n",
       "1                 True                NaN              NaN   \n",
       "2                 True                NaN              NaN   \n",
       "3                 True                NaN              NaN   \n",
       "4                 True                NaN              NaN   \n",
       "...                ...                ...              ...   \n",
       "3635             False                1.0             True   \n",
       "3636              True                NaN              NaN   \n",
       "3637              True                NaN              NaN   \n",
       "3638              True                NaN              NaN   \n",
       "3639              True                NaN              NaN   \n",
       "\n",
       "      Fourth_Layer_Score  Fourth_Layer_Pass  \n",
       "0                    NaN                NaN  \n",
       "1                    NaN                NaN  \n",
       "2                    NaN                NaN  \n",
       "3                    NaN                NaN  \n",
       "4                    NaN                NaN  \n",
       "...                  ...                ...  \n",
       "3635                 NaN                NaN  \n",
       "3636                 NaN                NaN  \n",
       "3637                 NaN                NaN  \n",
       "3638                 NaN                NaN  \n",
       "3639                 NaN                NaN  \n",
       "\n",
       "[3640 rows x 18 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92380f1f-20a9-4968-b702-9f4e3e6c160b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df1.to_csv('fuzzy_fail.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d06069f7-fae6-4984-a7aa-6d5865d75133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mismatched_data1_df.to_csv(\"fuzz_pass.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77d438d7-5377-42e9-a5da-a7800df37f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name1</th>\n",
       "      <th>name2</th>\n",
       "      <th>dsScore</th>\n",
       "      <th>flScore</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>labels</th>\n",
       "      <th>fuzzy_SS</th>\n",
       "      <th>fuzzy_flag</th>\n",
       "      <th>First_Layer_Score</th>\n",
       "      <th>First_Layer_Pass</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Second_Layer_Score</th>\n",
       "      <th>Second_Layer_Pass</th>\n",
       "      <th>Third_Layer_Score</th>\n",
       "      <th>Third_Layer_Pass</th>\n",
       "      <th>Fourth_Layer_Score</th>\n",
       "      <th>Fourth_Layer_Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47745945</td>\n",
       "      <td>GULASHAN DHAKAD</td>\n",
       "      <td>GULASHAN KUMAR DHAKER</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.364099</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48249550</td>\n",
       "      <td>M IMRAN KHAN</td>\n",
       "      <td>P  IMRAN KHAN</td>\n",
       "      <td>9.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45531859</td>\n",
       "      <td>SAVITRI DEVI</td>\n",
       "      <td>SAVITRI  KUSHWAH</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.323362</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49546728</td>\n",
       "      <td>Manoj Ramu Sangesaria</td>\n",
       "      <td>MANOJ RAMU VAGRI</td>\n",
       "      <td>58.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.450239</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46480124</td>\n",
       "      <td>MOHD BASIM</td>\n",
       "      <td>MOBASIM</td>\n",
       "      <td>75.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.347481</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47229736</td>\n",
       "      <td>BADE SIRISHA BHAVANI</td>\n",
       "      <td>Mrs Batchu Sirisha Bhavani</td>\n",
       "      <td>58.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.369884</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49205921</td>\n",
       "      <td>KUMKUM DEVI</td>\n",
       "      <td>KUMKUM TRADING</td>\n",
       "      <td>69.98</td>\n",
       "      <td>0.50</td>\n",
       "      <td>69.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.267688</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46740454</td>\n",
       "      <td>MAYA TEX</td>\n",
       "      <td>MAYA DEVI</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.061949</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48285564</td>\n",
       "      <td>MAMTA DEVI</td>\n",
       "      <td>MAMTA KUMARI</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.010639</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45517473</td>\n",
       "      <td>MARYAM HAJI MOHAMMED UBEDULLAH KHAN</td>\n",
       "      <td>MARIYAM BEE MOHAMMAD UBEDULLA KHAN</td>\n",
       "      <td>58.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47742847</td>\n",
       "      <td>Bharti Suyash</td>\n",
       "      <td>BHARTI DEVI</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.096496</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45660092</td>\n",
       "      <td>SWARJIT KUMAR SINGH</td>\n",
       "      <td>SWARJIT SINGH RATHORE</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.341611</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49117447</td>\n",
       "      <td>SHIV RATAN AGARWAL</td>\n",
       "      <td>SHIV RATAN NARENDERA KUMAR</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.251714</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48215232</td>\n",
       "      <td>JAYVEER GAMI</td>\n",
       "      <td>JAIVEER GAMIROOBI  DEVI</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.255151</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45920423</td>\n",
       "      <td>DINESH JAYSWAL</td>\n",
       "      <td>DINESH  KUMAR JAISWA</td>\n",
       "      <td>64.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.251770</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48663469</td>\n",
       "      <td>Fayyaz Ahmad Jameel Ahmad</td>\n",
       "      <td>FAYYAZ JAMEEL ANSARI</td>\n",
       "      <td>16.98</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.386758</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48145187</td>\n",
       "      <td>KADURI NARASAPPA NAIDU</td>\n",
       "      <td>Kanduru Narasappa</td>\n",
       "      <td>61.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>61.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.383434</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45975755</td>\n",
       "      <td>RITES KUMAR SHAW</td>\n",
       "      <td>Ritesh  Sah</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.171281</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47744036</td>\n",
       "      <td>DINABANDHU BHALLA</td>\n",
       "      <td>DINABANDHU  BISWAL</td>\n",
       "      <td>58.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>58.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.495925</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49005055</td>\n",
       "      <td>BALAPPA P TAKANNAVAR</td>\n",
       "      <td>BALLAPPA FAKIRAPPA TAKANNAVAR</td>\n",
       "      <td>39.82</td>\n",
       "      <td>0.33</td>\n",
       "      <td>39.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45321890</td>\n",
       "      <td>BIBI HAMIDA KHATOON</td>\n",
       "      <td>BIBI JUBAIDA KHATOON</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45820178</td>\n",
       "      <td>VIJAY PRAKASH PANDEY</td>\n",
       "      <td>JAY PRAKASH PANDEY S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>52.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>48639508</td>\n",
       "      <td>KANWAR LAL RATHORE</td>\n",
       "      <td>Kavar Lal Rathour</td>\n",
       "      <td>64.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>64.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.408602</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45894538</td>\n",
       "      <td>AJAY SINGH KUSHWAHA</td>\n",
       "      <td>ANJALI  KUSHWAHA</td>\n",
       "      <td>60.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>60.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.157607</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>47346899</td>\n",
       "      <td>BASANT KUMAR PAL</td>\n",
       "      <td>BASANT LAL</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.225827</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47773496</td>\n",
       "      <td>AVAYA KUMAR SETHY</td>\n",
       "      <td>ABHAY  SETHY</td>\n",
       "      <td>63.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>63.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.071463</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45629691</td>\n",
       "      <td>MOHAMMAD EKRAM</td>\n",
       "      <td>Ekram Fajal</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.385242</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46295510</td>\n",
       "      <td>SANGEETA MANGAL</td>\n",
       "      <td>Sangeeta  Mandavi</td>\n",
       "      <td>63.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>63.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.356712</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46185289</td>\n",
       "      <td>ARVIND CHAURSIYA</td>\n",
       "      <td>ARVIND KUMAR CHAURAS</td>\n",
       "      <td>64.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.395936</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51126241</td>\n",
       "      <td>Mohd Farman</td>\n",
       "      <td>FARMAN ALI</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.318670</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                name1  \\\n",
       "0   47745945                      GULASHAN DHAKAD   \n",
       "1   48249550                         M IMRAN KHAN   \n",
       "2   45531859                         SAVITRI DEVI   \n",
       "3   49546728                Manoj Ramu Sangesaria   \n",
       "4   46480124                           MOHD BASIM   \n",
       "5   47229736                 BADE SIRISHA BHAVANI   \n",
       "6   49205921                          KUMKUM DEVI   \n",
       "7   46740454                             MAYA TEX   \n",
       "8   48285564                           MAMTA DEVI   \n",
       "9   45517473  MARYAM HAJI MOHAMMED UBEDULLAH KHAN   \n",
       "10  47742847                        Bharti Suyash   \n",
       "11  45660092                  SWARJIT KUMAR SINGH   \n",
       "12  49117447                   SHIV RATAN AGARWAL   \n",
       "13  48215232                         JAYVEER GAMI   \n",
       "14  45920423                       DINESH JAYSWAL   \n",
       "15  48663469            Fayyaz Ahmad Jameel Ahmad   \n",
       "16  48145187               KADURI NARASAPPA NAIDU   \n",
       "17  45975755                     RITES KUMAR SHAW   \n",
       "18  47744036                    DINABANDHU BHALLA   \n",
       "19  49005055                 BALAPPA P TAKANNAVAR   \n",
       "20  45321890                  BIBI HAMIDA KHATOON   \n",
       "21  45820178                 VIJAY PRAKASH PANDEY   \n",
       "22  48639508                   KANWAR LAL RATHORE   \n",
       "23  45894538                  AJAY SINGH KUSHWAHA   \n",
       "24  47346899                     BASANT KUMAR PAL   \n",
       "25  47773496                    AVAYA KUMAR SETHY   \n",
       "26  45629691                       MOHAMMAD EKRAM   \n",
       "27  46295510                      SANGEETA MANGAL   \n",
       "28  46185289                     ARVIND CHAURSIYA   \n",
       "29  51126241                          Mohd Farman   \n",
       "\n",
       "                                 name2  dsScore  flScore  SCORE  labels  \\\n",
       "0                GULASHAN KUMAR DHAKER    59.58     0.50  59.58       0   \n",
       "1                        P  IMRAN KHAN     9.91     0.00   9.91       0   \n",
       "2                     SAVITRI  KUSHWAH     0.37     0.50   0.37       0   \n",
       "3                     MANOJ RAMU VAGRI    58.36     0.00  58.36       0   \n",
       "4                              MOBASIM    75.47     0.50  75.47       0   \n",
       "5           Mrs Batchu Sirisha Bhavani    58.23     0.00  58.23       0   \n",
       "6                       KUMKUM TRADING    69.98     0.50  69.98       0   \n",
       "7                            MAYA DEVI     0.63     0.50   0.63       0   \n",
       "8                         MAMTA KUMARI     0.40     0.50   0.40       0   \n",
       "9   MARIYAM BEE MOHAMMAD UBEDULLA KHAN    58.70     0.00  58.70       0   \n",
       "10                         BHARTI DEVI     0.95     0.50   0.95       0   \n",
       "11               SWARJIT SINGH RATHORE     0.38     0.50   0.38       0   \n",
       "12          SHIV RATAN NARENDERA KUMAR     1.85     0.00   1.85       0   \n",
       "13             JAIVEER GAMIROOBI  DEVI    39.92     0.50  39.92       0   \n",
       "14                DINESH  KUMAR JAISWA    64.18     0.50  64.18       0   \n",
       "15                FAYYAZ JAMEEL ANSARI    16.98     0.50  16.98       0   \n",
       "16                   Kanduru Narasappa    61.75     0.50  61.75       0   \n",
       "17                         Ritesh  Sah    54.29     0.50  54.29       0   \n",
       "18                  DINABANDHU  BISWAL    58.17     0.50  58.17       0   \n",
       "19       BALLAPPA FAKIRAPPA TAKANNAVAR    39.82     0.33  39.82       0   \n",
       "20                BIBI JUBAIDA KHATOON    55.28     0.00  55.28       0   \n",
       "21                JAY PRAKASH PANDEY S      NaN     0.75  52.49       0   \n",
       "22                   Kavar Lal Rathour    64.61     0.33  64.61       0   \n",
       "23                    ANJALI  KUSHWAHA    60.92     0.50  60.92       0   \n",
       "24                          BASANT LAL     7.86     0.50   7.86       0   \n",
       "25                        ABHAY  SETHY    63.27     0.50  63.27       0   \n",
       "26                         Ekram Fajal     1.14     0.50   1.14       0   \n",
       "27                   Sangeeta  Mandavi    63.53     0.50  63.53       0   \n",
       "28                ARVIND KUMAR CHAURAS    64.56     0.50  64.56       0   \n",
       "29                          FARMAN ALI     0.78     0.50   0.78       0   \n",
       "\n",
       "    fuzzy_SS  fuzzy_flag  First_Layer_Score  First_Layer_Pass  Prediction  \\\n",
       "0     0.8700           1             0.7375             False        True   \n",
       "1     0.9550           1             0.9100              True        True   \n",
       "2     0.8200           1             0.6425             False        True   \n",
       "3     0.8100           1             0.5225             False        True   \n",
       "4     0.8725           1             0.6775             False        True   \n",
       "5     0.8050           1             0.5275             False        True   \n",
       "6     0.8000           1             0.6625             False        True   \n",
       "7     0.8350           1             0.6600             False        True   \n",
       "8     1.0000           1             0.6375             False        True   \n",
       "9     0.8200           1             0.8350              True        True   \n",
       "10    0.8150           1             0.4100             False        True   \n",
       "11    0.8200           1             0.7350             False        True   \n",
       "12    0.8350           1             0.6825             False        True   \n",
       "13    0.8000           1             0.7125             False        True   \n",
       "14    0.8975           1             0.6850             False        True   \n",
       "15    0.8700           1             0.5150             False        True   \n",
       "16    0.8225           1             0.4925             False        True   \n",
       "17    0.8000           1             0.4525             False        True   \n",
       "18    0.8200           1             0.8000             False        True   \n",
       "19    0.8150           1             0.8150              True        True   \n",
       "20    0.8625           1             0.8625              True        True   \n",
       "21    0.8625           1             0.8625              True        True   \n",
       "22    0.8650           1             0.5750             False        True   \n",
       "23    0.8575           1             0.7075             False        True   \n",
       "24    0.9000           1             0.7075             False        True   \n",
       "25    0.8200           1             0.6375             False        True   \n",
       "26    0.8100           1             0.3625             False        True   \n",
       "27    0.8475           1             0.5175             False        True   \n",
       "28    0.8850           1             0.7250             False        True   \n",
       "29    0.8750           1             0.4025             False        True   \n",
       "\n",
       "    Second_Layer_Score Second_Layer_Pass  Third_Layer_Score  Third_Layer_Pass  \\\n",
       "0             1.364099              True                NaN               NaN   \n",
       "1                  NaN               NaN                NaN               NaN   \n",
       "2             1.323362              True                NaN               NaN   \n",
       "3             1.450239              True                NaN               NaN   \n",
       "4             1.347481              True                NaN               NaN   \n",
       "5             1.369884              True                NaN               NaN   \n",
       "6             1.267688              True                NaN               NaN   \n",
       "7             1.061949              True                NaN               NaN   \n",
       "8             1.010639              True                NaN               NaN   \n",
       "9                  NaN               NaN                NaN               NaN   \n",
       "10            1.096496              True                NaN               NaN   \n",
       "11            1.341611              True                NaN               NaN   \n",
       "12            1.251714              True                NaN               NaN   \n",
       "13            1.255151              True                NaN               NaN   \n",
       "14            1.251770              True                NaN               NaN   \n",
       "15            1.386758              True                NaN               NaN   \n",
       "16            1.383434              True                NaN               NaN   \n",
       "17            1.171281              True                NaN               NaN   \n",
       "18            1.495925              True                NaN               NaN   \n",
       "19                 NaN               NaN                NaN               NaN   \n",
       "20                 NaN               NaN                NaN               NaN   \n",
       "21                 NaN               NaN                NaN               NaN   \n",
       "22            1.408602              True                NaN               NaN   \n",
       "23            1.157607              True                NaN               NaN   \n",
       "24            1.225827              True                NaN               NaN   \n",
       "25            1.071463              True                NaN               NaN   \n",
       "26            1.385242              True                NaN               NaN   \n",
       "27            1.356712              True                NaN               NaN   \n",
       "28            1.395936              True                NaN               NaN   \n",
       "29            1.318670              True                NaN               NaN   \n",
       "\n",
       "    Fourth_Layer_Score  Fourth_Layer_Pass  \n",
       "0                  NaN                NaN  \n",
       "1                  NaN                NaN  \n",
       "2                  NaN                NaN  \n",
       "3                  NaN                NaN  \n",
       "4                  NaN                NaN  \n",
       "5                  NaN                NaN  \n",
       "6                  NaN                NaN  \n",
       "7                  NaN                NaN  \n",
       "8                  NaN                NaN  \n",
       "9                  NaN                NaN  \n",
       "10                 NaN                NaN  \n",
       "11                 NaN                NaN  \n",
       "12                 NaN                NaN  \n",
       "13                 NaN                NaN  \n",
       "14                 NaN                NaN  \n",
       "15                 NaN                NaN  \n",
       "16                 NaN                NaN  \n",
       "17                 NaN                NaN  \n",
       "18                 NaN                NaN  \n",
       "19                 NaN                NaN  \n",
       "20                 NaN                NaN  \n",
       "21                 NaN                NaN  \n",
       "22                 NaN                NaN  \n",
       "23                 NaN                NaN  \n",
       "24                 NaN                NaN  \n",
       "25                 NaN                NaN  \n",
       "26                 NaN                NaN  \n",
       "27                 NaN                NaN  \n",
       "28                 NaN                NaN  \n",
       "29                 NaN                NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatched_data1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd2903-6d11-4375-9d46-ffef5c1a0f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921c193-e7d3-4ac5-8422-5c3642ab4959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae73c1e-788e-47a5-9916-501ff4962a01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "True    3670\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fadd4f5-6939-4344-be83-287b82b39c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_393976/2110763975.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Prediction\"] = data.apply(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def check_initials_match(name1, name2):\n",
    "    initials1 = ''.join([word[0] for word in name1.split() if word])\n",
    "    initials2 = ''.join([word[0] for word in name2.split() if word])\n",
    "    return initials1.lower() == initials2.lower()\n",
    "\n",
    "# Function to check if any of the keywords are present in either name\n",
    "def check_keyword_present(name1, name2, keywords):\n",
    "    pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
    "    return bool(pattern.search(name1)) or bool(pattern.search(name2))\n",
    "\n",
    "# Define keywords list\n",
    "keywords = [\n",
    "    \"traders\", \"enterprise\", \"garments\", \"collection\", \"food\", \"clothes\",'fashion', \n",
    "    \"glass\", \"fittings\", \"digital\", \"kirana\", \"medical\", \"agency\", \n",
    "    \"security\", \"systems\", \"badges\", \"hospitality\", \"jewellers\", \n",
    "    \"ready-made\", \"store\", \"hospital\", \"restaurant\", \"auto\", \"center\", \n",
    "    \"dairy\", \"home\", \"products\", \"services\", \"furniture\", \"hardware\", \n",
    "    \"pharmacy\", \"stationery\", \"treatments\", \"nutrition\", \"wellness\", \n",
    "    \"sweets\", \"resort\", \"kitchen\", \"clothing\", \"fashion\", \"market\", \n",
    "    \"poultry\", \"seeds\", \"pesticides\", \"sales\", \"cafe\", \"clinic\", \n",
    "    \"supermart\", \"distributors\", \"automobiles\", \"electricity\", \n",
    "    \"electronics\", \"general\", \"provision\", \"fertilizers\", \"agriculture\", \n",
    "    \"beverages\", \"textiles\", \"plumbing\", \"supplies\", \"handicrafts\", \n",
    "    \"construction\", \"medical\", \"bakery\", \"tissue\", \"cleaning\", \n",
    "    \"appliances\", \"homecare\", \"kitchenware\", \"decor\", \"glass and fittings\",\n",
    "    \"interiors\", \"shopping\", \"crafts\", \"tools\", \"wholesale\", \n",
    "    \"retail\", \"outlet\", \"merchants\", \"trade\", \"distribution\", \n",
    "    \"solutions\", \"innovation\", \"consultancy\", \"services\", \"equipment\", \n",
    "    \"manufacturing\", \"exports\", \"imports\", \"packaging\", \"network\", \n",
    "    \"consultants\", \"transport\", \"moving\", \"storage\", \"logistics\", \n",
    "    \"construction\", \"real estate\", \"brokerage\", \"management\", \n",
    "    \"finance\", \"investment\", \"funding\", \"support\", \"technology\", \n",
    "    \"software\", \"applications\", \"digital marketing\", \"advertising\", \n",
    "    \"communication\", \"entertainment\", \"events\", \"tourism\", \"travel\", \n",
    "    \"transportation\", \"automotive\", \"services\", \"supply chain\", \n",
    "    \"fashion\", \"cosmetics\", \"beauty\", \"spa\", \"wellness\", \"glass and fitting\",\n",
    "    \"personal care\", \"gifts\", \"custom\", \"specialty\", \"craftsmanship\", \n",
    "    \"fashions\", \"motors\", \"enterprises\", \"garment\", \"cloth centre\", \"mart\", \n",
    "    \"foods\", \"silk and readymade\", \"wool centre\", \"jewellery\", \"mill\", \n",
    "    \"farms\", \"farm\", \"electrical\", \"egg centre\", \"centre\", \n",
    "    \"vegetable and fruits\", \"vegetables\", \"fruits\", \"pvt\", \"pvt ltd\", \n",
    "    \"limited\", \"solutions\", \"energies\", \"photo\", \"studio\", \"works\", \n",
    "    \"associates\", \"medico\", \"agencies\", \"diagnosis\", \"cool drinks\", \n",
    "    \"drinks\", \"care\", \"liquor\", \"automobiles\", \"materials\", \"diagnostics\", \n",
    "    \"provision\", \"trader\", \"farms\", \"farm\", \"stations\", \"restaurant\", \n",
    "    \"creations\", \"travels\", \"hardware\", \"printers\", \"graphics\", \n",
    "    \"fertilisers\", \"house\", \"studio\", \"private\", \"appliances\", \"steels\", \n",
    "    \"shop\", \"metals\", \"international\", \"jwellers\", \"corporation\", \n",
    "    \"dresses\", \"industries\", \"electricals\", \"company\", \"lim\", \"colddrinks\", \n",
    "    \"electron\", \"medicines\", \"llc\", \"computers\", \"hotel\", \"spa\", \n",
    "    \"cosmetics\", \"telecom\", \"sarees\", \"petroleums\", \"bhandar\",'store','stores', \n",
    "    \"surgical\", \"wines\", \"constructions\", \"shoppy\", \"lab\", \"builders\", \n",
    "    \"footwear\", \"wear\", \"shoe\", \"repair\", \"ventures\", \"paint\", \"depot\",'cake','chinies',\n",
    "    \"tent\", \"decorators\", \"communications\", \"pharmacy\", \"products\",'textile','CERAMIC','Pharmaceuticals',\n",
    "]\n",
    "\n",
    "\n",
    "#-------------------\n",
    "# Function to apply initials and keywords checks\n",
    "def apply_initials_and_keyword_checks(name1, name2, keywords):\n",
    "    if check_initials_match(name1, name2):\n",
    "        if check_keyword_present(name1, name2, keywords):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "data[\"Prediction\"] = data.apply(\n",
    "    lambda x: apply_initials_and_keyword_checks(x['name1'], x['name2'], keywords) if x[\"Prediction\"] else x[\"Prediction\"],\n",
    "    axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb810a38-aa54-4a94-b714-ab7f84821f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "False    3614\n",
       "True       56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d28639-5e09-4404-bb24-0b771afd117a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv('Pass.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5571d0-5735-4c42-a17d-d11552a75cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffff08-2f57-483f-ace2-e56c6a5a0a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb24b3-6a71-49ba-800f-72bebb3e619b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dd1a7-af90-4548-8c49-2a4eb504620e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886e695-b89b-4b72-b1f7-1f1d24f63727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e877438-a846-417c-b6ad-9bf3565f9a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score, \n",
    "#     confusion_matrix, \n",
    "#     precision_score, \n",
    "#     recall_score, \n",
    "#     f1_score, \n",
    "#     roc_auc_score, \n",
    "#     classification_report\n",
    "# )\n",
    "\n",
    "# def process_name_matching(file_path):\n",
    "# # def process_name_matching(file_path, num_rows=10):\n",
    "\n",
    "#     # Load data\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     # df = pd.read_csv(file_path, nrows=num_rows)\n",
    "#     threshold = 0.80\n",
    "\n",
    "#     # Layer 1: Fuzzy Matching Without Preprocessing\n",
    "#     df[\"First_Layer_Score\"] = df.apply(lambda x: calculate_fuzzy_similarity(x['name1'], x['name2']), axis=1)\n",
    "#     df[\"First_Layer_Pass\"] = df[\"First_Layer_Score\"] >= threshold\n",
    "#     df_layer2 = df[~df[\"First_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 2: Preprocessed Fuzzy Matching\n",
    "#     df_layer2[\"Second_Layer_Score\"] = df_layer2.apply(lambda x: calculate_fuzzy_similarity_processed(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer2[\"Second_Layer_Pass\"] = df_layer2[\"Second_Layer_Score\"] >= threshold\n",
    "#     df_layer3 = df_layer2[~df_layer2[\"Second_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 3: Initials Matching Without Preprocessing\n",
    "#     df_layer3[\"Third_Layer_Score\"] = df_layer3.apply(lambda x: check_initial_similarity(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer3[\"Third_Layer_Pass\"] = df_layer3[\"Third_Layer_Score\"] >= threshold\n",
    "#     df_layer4 = df_layer3[~df_layer3[\"Third_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 4: Model and Phonetic Matching\n",
    "#     df_layer4[\"Fourth_Layer_Score\"] = df_layer4.apply(lambda x: name_match(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer4[\"Fourth_Layer_Pass\"] = df_layer4[\"Fourth_Layer_Score\"] >= threshold\n",
    "    \n",
    "\n",
    "#     # Save layers and results\n",
    "#     df_combined = pd.concat([\n",
    "#         df[df[\"First_Layer_Pass\"]],\n",
    "#         df_layer2[df_layer2[\"Second_Layer_Pass\"]],\n",
    "#         df_layer3[df_layer3[\"Third_Layer_Pass\"]],\n",
    "#         df_layer4[df_layer4[\"Fourth_Layer_Pass\"]],\n",
    "\n",
    "#     ])\n",
    "#     df_combined.to_csv(\"File.csv\",index=False)\n",
    "#     # Updating Prediction status based on layer passes\n",
    "#     df[\"Prediction\"] = False\n",
    "#     df.loc[df[\"First_Layer_Pass\"], \"Prediction\"] = True\n",
    "#     df.loc[df_layer2.index[df_layer2[\"Second_Layer_Pass\"]], \"Prediction\"] = True\n",
    "#     df.loc[df_layer3.index[df_layer3[\"Third_Layer_Pass\"]], \"Prediction\"] = True\n",
    "#     df.loc[df_layer4.index[df_layer4[\"Fourth_Layer_Pass\"]], \"Prediction\"] = True\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     # df[\"Layer0_Pass\"] = df.get(\"Layer0_Pass\", None)\n",
    "#     df[\"First_Layer_Score\"] = df.get(\"First_Layer_Score\", None)\n",
    "#     df[\"First_Layer_Pass\"] = df.get(\"First_Layer_Pass\", None)\n",
    "#     df[\"Second_Layer_Score\"] = df_layer2.get(\"Second_Layer_Score\", None)\n",
    "#     df[\"Second_Layer_Pass\"] = df_layer2.get(\"Second_Layer_Pass\", None)\n",
    "#     df[\"Third_Layer_Score\"] = df_layer3.get(\"Third_Layer_Score\", None)\n",
    "#     df[\"Third_Layer_Pass\"] = df_layer3.get(\"Third_Layer_Pass\", None)\n",
    "#     df[\"Fourth_Layer_Score\"] = df_layer4.get(\"Fourth_Layer_Score\", None)\n",
    "#     df[\"Fourth_Layer_Pass\"] = df_layer4.get(\"Fourth_Layer_Pass\", None)\n",
    "    \n",
    "\n",
    "\n",
    "#     df.to_csv('Api_fun_result.csv')\n",
    "\n",
    "\n",
    "#     # Performance metrics\n",
    "#     y_true = df['labels']\n",
    "#     y_pred = df['Prediction']\n",
    "#     y_scores = df[\"First_Layer_Score\"]  # Use the scores for AUC\n",
    "\n",
    "#     metrics = {\n",
    "#         \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "#         \"precision\": precision_score(y_true, y_pred),\n",
    "#         \"recall\": recall_score(y_true, y_pred),\n",
    "#         \"f1_score\": f1_score(y_true, y_pred),\n",
    "#         \"roc_auc_score\": roc_auc_score(y_true, y_scores),\n",
    "#         \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "#         \"classification_report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "#     }\n",
    "\n",
    "#     # Correlation matrix (only numeric columns)\n",
    "#     correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "#     return metrics, df, df_combined, correlation_matrix\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"2_lakh_NM_Manually.csv\", num_rows=10)\n",
    "#     metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"20k_balaned_data.csv\")\n",
    "\n",
    "#     # Print the confusion matrix\n",
    "#     cm = metrics[\"confusion_matrix\"]\n",
    "#     cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(cm_df)\n",
    "\n",
    "#     # Print the correlation matrix\n",
    "#     print(\"\\nCorrelation Matrix:\")\n",
    "#     print(correlation_matrix)\n",
    "\n",
    "#     # Print other metrics\n",
    "#     print(\"\\nMetrics:\")\n",
    "#     print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "#     print(f\"Precision: {metrics['precision']}\")\n",
    "#     print(f\"Recall: {metrics['recall']}\")\n",
    "#     print(f\"F1 Score: {metrics['f1_score']}\")\n",
    "#     print(f\"AUC: {metrics['roc_auc_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cda0e-328d-4c5e-8fa0-d1230d1050c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa077da-4a40-4321-ba0d-42c396b6d165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf7c74-54e1-4afd-980a-8487b57d45c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e501fbb-71d8-47f8-9a93-e6752bd54ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1a98c-3f05-484d-8918-178250529334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881c46e-ace9-4034-bbff-52d09a1bd6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2d0e3-0102-42dd-8294-855e2c104172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce86eae-5823-4a0b-a23e-7b9ec4701de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b0c4a55-4d21-471e-82b0-ec44cce5e1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword match found: False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f863001-18a0-46eb-b975-a6fe1279597a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf64d58-e1a9-4fd4-87eb-d97c7a1e7ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d426c10-56b4-42ee-8dbe-872cde3174fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def process_name_matching_two(name1, name2):\n",
    "#     threshold = 0.80\n",
    "\n",
    "#     # Layer 1: Fuzzy Matching Without Preprocessing\n",
    "#     first_layer_score = calculate_fuzzy_similarity(name1, name2)\n",
    "#     if first_layer_score >= threshold:\n",
    "#         return first_layer_score\n",
    "\n",
    "#     # Layer 2: Preprocessed Fuzzy Matching\n",
    "#     second_layer_score = calculate_fuzzy_similarity_processed(name1, name2)\n",
    "#     if second_layer_score >= threshold:\n",
    "#         return second_layer_score\n",
    "\n",
    "#     # Layer 3: Initials Matching Without Preprocessing\n",
    "#     third_layer_score = check_initial_similarity(name1, name2)\n",
    "#     if third_layer_score >= threshold:\n",
    "#         return third_layer_score\n",
    "\n",
    "#     # Layer 4: Model and Phonetic Matching\n",
    "#     fourth_layer_score = name_match(name1, name2)\n",
    "#     if fourth_layer_score >= threshold:\n",
    "#         return fourth_layer_score\n",
    "\n",
    "#     # If none of the layers meet the threshold, return the last computed score or None\n",
    "#     return fourth_layer_score\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     name1 = \"Manmeet Singh \"\n",
    "#     name2 = \"Singh Manmeet\"\n",
    "#     similarity_score = process_name_matching_two(name1, name2)\n",
    "#     print(f\"\\nSimilarity score between '{name1}' and '{name2}': {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "392910b2-273d-4d90-b778-38fd460ca33c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         6661         3670\n",
      "Actual 1            1        10170\n",
      "\n",
      "Correlation Matrix:\n",
      "                         id  szFlag   dsScore  szScore   flScore     SCORE  \\\n",
      "id                 1.000000     NaN -0.027826      NaN  0.019066  0.020089   \n",
      "szFlag                  NaN     NaN       NaN      NaN       NaN       NaN   \n",
      "dsScore           -0.027826     NaN  1.000000      NaN  0.100611  0.998056   \n",
      "szScore                 NaN     NaN       NaN      NaN       NaN       NaN   \n",
      "flScore            0.019066     NaN  0.100611      NaN  1.000000  0.893569   \n",
      "SCORE              0.020089     NaN  0.998056      NaN  0.893569  1.000000   \n",
      "labels             0.020322     NaN  0.516676      NaN  0.930848  0.935229   \n",
      "First_Layer_Score  0.006455     NaN  0.449603      NaN  0.862994  0.850939   \n",
      "\n",
      "                     labels  First_Layer_Score  \n",
      "id                 0.020322           0.006455  \n",
      "szFlag                  NaN                NaN  \n",
      "dsScore            0.516676           0.449603  \n",
      "szScore                 NaN                NaN  \n",
      "flScore            0.930848           0.862994  \n",
      "SCORE              0.935229           0.850939  \n",
      "labels             1.000000           0.856413  \n",
      "First_Layer_Score  0.856413           1.000000  \n",
      "\n",
      "Metrics:\n",
      "Accuracy: 0.8209442981172569\n",
      "Precision: 0.7348265895953757\n",
      "Recall: 0.9999016812506145\n",
      "F1 Score: 0.8471117404522926\n",
      "AUC: 0.9814145063561773\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score, \n",
    "#     confusion_matrix, \n",
    "#     precision_score, \n",
    "#     recall_score, \n",
    "#     f1_score, \n",
    "#     roc_auc_score, \n",
    "#     classification_report\n",
    "# )\n",
    "\n",
    "# def process_name_matching(file_path):\n",
    "# # def process_name_matching(file_path, num_rows=10):\n",
    "\n",
    "#     # Load data\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     # df = pd.read_csv(file_path, nrows=num_rows)\n",
    "#     threshold = 0.80\n",
    "\n",
    "#     # Layer 1: Fuzzy Matching Without Preprocessing\n",
    "#     df[\"First_Layer_Score\"] = df.apply(lambda x: calculate_fuzzy_similarity(x['name1'], x['name2']), axis=1)\n",
    "#     df[\"First_Layer_Pass\"] = df[\"First_Layer_Score\"] >= threshold\n",
    "#     df_layer2 = df[~df[\"First_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 2: Preprocessed Fuzzy Matching\n",
    "#     df_layer2[\"Second_Layer_Score\"] = df_layer2.apply(lambda x: calculate_fuzzy_similarity_processed(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer2[\"Second_Layer_Pass\"] = df_layer2[\"Second_Layer_Score\"] >= threshold\n",
    "#     df_layer3 = df_layer2[~df_layer2[\"Second_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 3: Initials Matching Without Preprocessing\n",
    "#     df_layer3[\"Third_Layer_Score\"] = df_layer3.apply(lambda x: check_initial_similarity(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer3[\"Third_Layer_Pass\"] = df_layer3[\"Third_Layer_Score\"] >= threshold\n",
    "#     df_layer4 = df_layer3[~df_layer3[\"Third_Layer_Pass\"]].copy()\n",
    "\n",
    "#     # Layer 4: Model and Phonetic Matching\n",
    "#     df_layer4[\"Fourth_Layer_Score\"] = df_layer4.apply(lambda x: name_match(x['name1'], x['name2']), axis=1)\n",
    "#     df_layer4[\"Fourth_Layer_Pass\"] = df_layer4[\"Fourth_Layer_Score\"] >= threshold\n",
    "\n",
    "#     # Save layers and results\n",
    "#     df_combined = pd.concat([\n",
    "#         df[df[\"First_Layer_Pass\"]],\n",
    "#         df_layer2[df_layer2[\"Second_Layer_Pass\"]],\n",
    "#         df_layer3[df_layer3[\"Third_Layer_Pass\"]],\n",
    "#         df_layer4[df_layer4[\"Fourth_Layer_Pass\"]]\n",
    "#     ])\n",
    "#     df_combined.to_csv(\"File.csv\",index=False)\n",
    "#     # Updating Prediction status based on layer passes\n",
    "#     df[\"Prediction\"] = False\n",
    "#     df.loc[df[\"First_Layer_Pass\"], \"Prediction\"] = True\n",
    "#     df.loc[df_layer2.index[df_layer2[\"Second_Layer_Pass\"]], \"Prediction\"] = True\n",
    "#     df.loc[df_layer3.index[df_layer3[\"Third_Layer_Pass\"]], \"Prediction\"] = True\n",
    "#     df.loc[df_layer4.index[df_layer4[\"Fourth_Layer_Pass\"]], \"Prediction\"] = True\n",
    "\n",
    "#     # Performance metrics\n",
    "#     y_true = df['labels']\n",
    "#     y_pred = df['Prediction']\n",
    "#     y_scores = df[\"First_Layer_Score\"]  # Use the scores for AUC\n",
    "\n",
    "#     metrics = {\n",
    "#         \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "#         \"precision\": precision_score(y_true, y_pred),\n",
    "#         \"recall\": recall_score(y_true, y_pred),\n",
    "#         \"f1_score\": f1_score(y_true, y_pred),\n",
    "#         \"roc_auc_score\": roc_auc_score(y_true, y_scores),\n",
    "#         \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "#         \"classification_report\": classification_report(y_true, y_pred, output_dict=True)\n",
    "#     }\n",
    "\n",
    "#     # Correlation matrix (only numeric columns)\n",
    "#     correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "#     return metrics, df, df_combined, correlation_matrix\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"2_lakh_NM_Manually.csv\", num_rows=10)\n",
    "#     metrics, full_data, combined_data, correlation_matrix = process_name_matching(\"20k_balaned_data.csv\")\n",
    "\n",
    "#     # Print the confusion matrix\n",
    "#     cm = metrics[\"confusion_matrix\"]\n",
    "#     cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(cm_df)\n",
    "\n",
    "#     # Print the correlation matrix\n",
    "#     print(\"\\nCorrelation Matrix:\")\n",
    "#     print(correlation_matrix)\n",
    "\n",
    "#     # Print other metrics\n",
    "#     print(\"\\nMetrics:\")\n",
    "#     print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "#     print(f\"Precision: {metrics['precision']}\")\n",
    "#     print(f\"Recall: {metrics['recall']}\")\n",
    "#     print(f\"F1 Score: {metrics['f1_score']}\")\n",
    "#     print(f\"AUC: {metrics['roc_auc_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7c976-407f-47b1-8afd-61936697a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24a3bed8-e83a-4992-bdd9-97080896755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword match found: False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Layer 0 - Check for Keyword Match\n",
    "def check_keyword_match(name1, name2, keywords):\n",
    "    pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
    "    name1_contains_keyword = bool(pattern.search(name1))\n",
    "    name2_contains_keyword = bool(pattern.search(name2))\n",
    "    return name1_contains_keyword and name2_contains_keyword\n",
    "\n",
    "# Provided keywords list\n",
    "keywords = [\n",
    "    \"traders\", \"enterprise\", \"garments\", \"collection\", \"food\", \"clothes\", \n",
    "    \"glass\", \"fittings\", \"digital\", \"kirana\", \"medical\", \"agency\", \n",
    "    \"security\", \"systems\", \"badges\", \"hospitality\", \"jewellers\", \n",
    "    \"ready-made\", \"store\", \"hospital\", \"restaurant\", \"auto\", \"center\", \n",
    "    \"dairy\", \"home\", \"products\", \"services\", \"furniture\", \"hardware\", \n",
    "    \"pharmacy\", \"stationery\", \"treatments\", \"nutrition\", \"wellness\", \n",
    "    \"sweets\", \"resort\", \"kitchen\", \"clothing\", \"fashion\", \"market\", \n",
    "    \"poultry\", \"seeds\", \"pesticides\", \"sales\", \"cafe\", \"clinic\", \n",
    "    \"supermart\", \"distributors\", \"automobiles\", \"electricity\", \n",
    "    \"electronics\", \"general\", \"provision\", \"fertilizers\", \"agriculture\", \n",
    "    \"beverages\", \"textiles\", \"plumbing\", \"supplies\", \"handicrafts\", \n",
    "    \"construction\", \"medical\", \"bakery\", \"tissue\", \"cleaning\", \n",
    "    \"appliances\", \"homecare\", \"kitchenware\", \"decor\", \"glass and fittings\",\n",
    "    \"interiors\", \"shopping\", \"crafts\", \"tools\", \"wholesale\", \n",
    "    \"retail\", \"outlet\", \"merchants\", \"trade\", \"distribution\", \n",
    "    \"solutions\", \"innovation\", \"consultancy\", \"services\", \"equipment\", \n",
    "    \"manufacturing\", \"exports\", \"imports\", \"packaging\", \"network\", \n",
    "    \"consultants\", \"transport\", \"moving\", \"storage\", \"logistics\", \n",
    "    \"construction\", \"real estate\", \"brokerage\", \"management\", \n",
    "    \"finance\", \"investment\", \"funding\", \"support\", \"technology\", \n",
    "    \"software\", \"applications\", \"digital marketing\", \"advertising\", \n",
    "    \"communication\", \"entertainment\", \"events\", \"tourism\", \"travel\", \n",
    "    \"transportation\", \"automotive\", \"services\", \"supply chain\", \n",
    "    \"fashion\", \"cosmetics\", \"beauty\", \"spa\", \"wellness\", \"glass and fitting\",\n",
    "    \"personal care\", \"gifts\", \"custom\", \"specialty\", \"craftsmanship\", \n",
    "    \"fashions\", \"motors\", \"enterprises\", \"garment\", \"cloth centre\", \"mart\", \n",
    "    \"foods\", \"silk and readymade\", \"wool centre\", \"jewellery\", \"mill\", \n",
    "    \"farms\", \"farm\", \"electrical\", \"egg centre\", \"centre\", \n",
    "    \"vegetable and fruits\", \"vegetables\", \"fruits\", \"pvt\", \"pvt ltd\", \n",
    "    \"limited\", \"solutions\", \"energies\", \"photo\", \"studio\", \"works\", \n",
    "    \"associates\", \"medico\", \"agencies\", \"diagnosis\", \"cool drinks\", \n",
    "    \"drinks\", \"care\", \"liquor\", \"automobiles\", \"materials\", \"diagnostics\", \n",
    "    \"provision\", \"trader\", \"farms\", \"farm\", \"stations\", \"restaurant\", \n",
    "    \"creations\", \"travels\", \"hardware\", \"printers\", \"graphics\", \n",
    "    \"fertilisers\", \"house\", \"studio\", \"private\", \"appliances\", \"steels\", \n",
    "    \"shop\", \"metals\", \"international\", \"jwellers\", \"corporation\", \n",
    "    \"dresses\", \"industries\", \"electricals\", \"company\", \"lim\", \"colddrinks\", \n",
    "    \"electron\", \"medicines\", \"llc\", \"computers\", \"hotel\", \"spa\", \n",
    "    \"cosmetics\", \"telecom\", \"sarees\", \"petroleums\", \"bhandar\", \n",
    "    \"surgical\", \"wines\", \"constructions\", \"shoppy\", \"lab\", \"builders\", \n",
    "    \"footwear\", \"wear\", \"shoe\", \"repair\", \"ventures\", \"paint\", \"depot\", \n",
    "    \"tent\", \"decorators\", \"communications\", \"pharmacy\", \"products\"\n",
    "]\n",
    "\n",
    "# # Layer 0 - Check for Keyword Match\n",
    "# def check_keyword_match(name1, name2, keywords):\n",
    "#     pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
    "#     name1_contains_keyword = bool(pattern.search(name1))\n",
    "#     name2_contains_keyword = bool(pattern.search(name2))\n",
    "#     return name1_contains_keyword and name2_contains_keyword\n",
    "\n",
    "\n",
    "# Test examples\n",
    "name1 = \"Royal Traders\"\n",
    "name2 = \"Green Leaf Pharmaceuticals\"\n",
    "\n",
    "# Check if any keywords are found in either name\n",
    "result = check_keyword_match(name1, name2, keywords)\n",
    "print(\"Keyword match found:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ec539-fd72-4eb2-b697-2ee300aad671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb9342-0ce6-4e1c-9c7e-a6f9d9b0958b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff042c7b-8344-49aa-9720-2ba652cedfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_keyword_match(name1, name2, keywords):\n",
    "    # Create a regex pattern to match any of the keywords, case-insensitive\n",
    "    pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
    "    \n",
    "    # Check if name1 and name2 contain any of the keywords\n",
    "    name1_contains_keyword = bool(pattern.search(name1))\n",
    "    name2_contains_keyword = bool(pattern.search(name2))\n",
    "\n",
    "    # Return True if both name1 and name2 contain at least one keyword, else False\n",
    "    return int(name1_contains_keyword and name2_contains_keyword)\n",
    "\n",
    "# Example usage\n",
    "keywords = [\n",
    "    \"traders\", \"enterprise\", \"garments\", \"collection\", \"food\", \"clothes\", \n",
    "    \"glass\", \"fittings\", \"digital\", \"kirana\", \"medical\", \"agency\", \n",
    "    \"security\", \"systems\", \"badges\", \"hospitality\", \"jewellers\", \n",
    "    \"ready-made\", \"store\", \"hospital\", \"restaurant\", \"auto\", \"center\", \n",
    "    \"dairy\", \"home\", \"products\", \"services\", \"furniture\", \"hardware\", \n",
    "    \"pharmacy\", \"stationery\", \"treatments\", \"nutrition\", \"wellness\", \n",
    "    \"sweets\", \"resort\", \"kitchen\", \"clothing\", \"fashion\", \"market\", \n",
    "    \"poultry\", \"seeds\", \"pesticides\", \"sales\", \"cafe\", \"clinic\", \n",
    "    \"supermart\", \"distributors\", \"automobiles\", \"electricity\", \n",
    "    \"electronics\", \"general\", \"provision\", \"fertilizers\", \"agriculture\", \n",
    "    \"beverages\", \"textiles\", \"plumbing\", \"supplies\", \"handicrafts\", \n",
    "    \"construction\", \"medical\", \"bakery\", \"tissue\", \"cleaning\", \n",
    "    \"appliances\", \"homecare\", \"food\", \"kitchenware\", \"decor\", \n",
    "    \"interiors\", \"shopping\", \"crafts\", \"tools\", \"wholesale\", \n",
    "    \"retail\", \"outlet\", \"merchants\", \"trade\", \"distribution\", \n",
    "    \"solutions\", \"innovation\", \"consultancy\", \"services\", \"equipment\", \n",
    "    \"manufacturing\", \"exports\", \"imports\", \"packaging\", \"network\", \n",
    "    \"consultants\", \"transport\", \"moving\", \"storage\", \"logistics\", \n",
    "    \"construction\", \"real estate\", \"brokerage\", \"management\", \n",
    "    \"finance\", \"investment\", \"funding\", \"support\", \"technology\", \n",
    "    \"software\", \"applications\", \"digital marketing\", \"advertising\", \n",
    "    \"communication\", \"entertainment\", \"events\", \"tourism\", \"travel\", \n",
    "    \"transportation\", \"automotive\", \"services\", \"supply chain\", \n",
    "    \"fashion\", \"cosmetics\", \"beauty\", \"spa\", \"wellness\", \n",
    "    \"personal care\", \"gifts\", \"custom\", \"specialty\", \"craftsmanship\"\n",
    "]\n",
    "\n",
    "name1 = \"MOHAMMED MOHSIN MOHAMMED SALIM SHAIKH\"\n",
    "name2 = \"TAJ ENTERPRISES\"\n",
    "result = check_keyword_match(name1, name2, keywords)\n",
    "print(\"Prediction:\", result)  # This will print \"Prediction: True\" if both contain keywords, else \"False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ccd11-a079-4db3-a942-2cabe6198808",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 min bssss"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
